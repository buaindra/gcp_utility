{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyNt2e4UOlu4NJqEAtzy71",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buaindra/gcp_utility/blob/main/gcp/data_pipeline_poc/BQ_ML_Log_Analysis/log_analysis_gcp_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log data analysisusing BQ-ML"
      ],
      "metadata": {
        "id": "hvz3WF1a-PtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Log Analysis blogs\n",
        "1. https://aws.amazon.com/blogs/opensource/introducing-aws-security-analytics-bootstrap/"
      ],
      "metadata": {
        "id": "YGc2RXmeCp9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Ref\n",
        "1. DDOS Network Logs: https://www.kaggle.com/datasets/jacobvs/ddos-attack-network-logs"
      ],
      "metadata": {
        "id": "lGS3wS2i-YWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to download data using kaggle api\n",
        "#### ref: https://github.com/Kaggle/kaggle-api\n",
        "1. sign-in to kaggle site.\n",
        "2. hover the mouse over your profile photo.\n",
        "3. select \"account\".\n",
        "4. then go-to api section and click on \"create new api token\".\n",
        "5. it will download the kaggle.json file which has kaggle user id and kaggle key."
      ],
      "metadata": {
        "id": "bWRkWfe2C5T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle --upgrade"
      ],
      "metadata": {
        "id": "N-P0LU8HC4kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2WTJXsL-E20"
      },
      "outputs": [],
      "source": [
        "!export KAGGLE_USERNAME=buaindra\n",
        "!export KAGGLE_KEY=15b6f914804e6beef1e16662d53de05a"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Client Approach"
      ],
      "metadata": {
        "id": "PavCHIC6OLG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google CLoud Storage\n",
        "1. Google Storage Doc: https://cloud.google.com/storage/docs/gsutil/commands/mb\n"
      ],
      "metadata": {
        "id": "xWaJEYGpMFeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigquery Machine Leraning\n",
        "1. Google BQ ML Doc: https://cloud.google.com/bigquery-ml/docs/introduction\n",
        "2. https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-e2e-journey\n",
        "2. QWIKLABS: https://partner.cloudskillsboost.google/focuses/14821?parent=catalog"
      ],
      "metadata": {
        "id": "nlg8TCqv6o3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning\n",
        "1. Google ML Doc: https://developers.google.com/machine-learning/glossary/#model\n",
        "2. Youtube Linear vs Logistic Regression: https://www.youtube.com/watch?v=OCwZyYH14uw"
      ],
      "metadata": {
        "id": "3PJoKUUQONLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Shared by Christian\n",
        "### http://www.fukuda-lab.org/mawilab/index.html\n",
        "\n",
        "## BQ-ML Ref:\n",
        "1. https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-detect-anomalies#mldetect_anomalies_function"
      ],
      "metadata": {
        "id": "_DelWwrV_srX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default Parameter in cloud-shell"
      ],
      "metadata": {
        "id": "xc60lE1J6bfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export PROJECT_ID=\"$(gcloud config get-value project)\"\n",
        "export LOCATION=\"us-central1\"\n",
        "export BQ_DATASET=\"test_dataset\"\n",
        "export BQ_TABLE=\"test_table\"\n",
        "export BUCKET=\"${PROJECT_ID}_bucket\""
      ],
      "metadata": {
        "id": "ZQz_vnX03yzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enable the below Google APIs"
      ],
      "metadata": {
        "id": "JiKzInzpFPq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcloud services enable storage.googleapis.com\n",
        "gcloud services enable bigquery.googleapis.com"
      ],
      "metadata": {
        "id": "N-drqpSeFPHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create GCS Bucket"
      ],
      "metadata": {
        "id": "kE5kp3l1AEse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gsutil mb -c standard -l ${LOCATION} gs://${BUCKET}"
      ],
      "metadata": {
        "id": "mKvkZuf5AKkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Bigquery Dataset"
      ],
      "metadata": {
        "id": "e5Kq2tyT6g4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bq --location=${LOCATION} mk \\\n",
        "--dataset \\\n",
        "--default_table_expiration 3600 \\\n",
        "${PROJECT_ID}:${BQ_DATASET}"
      ],
      "metadata": {
        "id": "C9M23pD03tUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Source data\n",
        "1. Load the downloaded logs data into gcs bucket\n",
        "2. create local **schema_json.json** file and put below schema json inside the file. **schema file should be placed locally**."
      ],
      "metadata": {
        "id": "tC_wEXIdzW2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[\n",
        "  {\n",
        "    \"name\": \"anomalyID\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"a unique anomaly identifier. Several lines in the CSV file can describe different sets of packets that belong to the same anomaly. The anomalyID field permits to identify lines that refer to the same anomaly.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"srcIP\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the source IP address of the identified anomalous traffic (optional).\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"srcPort\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the source port of the identified anomalous traffic (optional).\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"dstIP\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the destination IP address of the identified anomalous traffic (optional).\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"dstPort\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the destination port of the identified anomalous traffic (optional).\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"taxonomy\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the category assigned to the anomaly using the taxonomy for backbone traffic anomalies.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"heuristic\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the code assigned to the anomaly using simple heuristic based on port number, TCP flags and ICMP code.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"distance\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the difference Dn-Da, see XML Schema (admd).\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"nbDetectors\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the number of configurations (detector and parameter tuning) that reported the anomaly.\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"label\",\n",
        "    \"type\": \"STRING\",\n",
        "    \"mode\": \"NULLABLE\",\n",
        "    \"description\": \"is the MAWILab label assigned to the anomaly, it can be either: anomalous, suspicious, or notice.\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "matWSngd6XJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data from GCS to BQ (ELT)"
      ],
      "metadata": {
        "id": "XgWLOKYuAMJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export FILE_NAME01=\"20210528_anomalous_suspicious.csv\"\n",
        "export BQ_TABLE01=\"20210528_anomalous_suspicious\"\n",
        "\n",
        "bq --location=${LOCATION} load \\\n",
        "--autodetect \\\n",
        "--skip_leading_rows=1 \\\n",
        "--source_format=CSV \\\n",
        "${PROJECT_ID}:${BQ_DATASET}.${BQ_TABLE01} \\\n",
        "gs://${BUCKET}/${FILE_NAME01}\n"
      ],
      "metadata": {
        "id": "NDgRT0r9o9rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export FILE_NAME02=\"20210528_notice.csv\"\n",
        "export BQ_TABLE02=\"20210528_notice\"\n",
        "\n",
        "\n",
        "bq --location=${LOCATION} load \\\n",
        "--autodetect \\\n",
        "--skip_leading_rows=1 \\\n",
        "--source_format=CSV \\\n",
        "${PROJECT_ID}:${BQ_DATASET}.${BQ_TABLE02} \\\n",
        "gs://${BUCKET}/${FILE_NAME02}"
      ],
      "metadata": {
        "id": "ISUnxUpa8Zie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create training and testing table \n",
        "1. Do some pre-processing the data first\n",
        "2. then combine these 2 tables and take 80%-20% distribution of the training and testing dataset"
      ],
      "metadata": {
        "id": "5pIb8tRtrfeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create or replace table `test_dataset.ml_dataset`(\n",
        "  id INT64,\n",
        "  anomalyID INT64,\n",
        "  srcIP STRING, \n",
        "  srcPort STRING, \n",
        "  dstIP STRING, \n",
        "  dstPort STRING, \n",
        "  taxonomy STRING, \n",
        "  heuristic STRING, \n",
        "  distance STRING, \n",
        "  nbDetectors STRING, \n",
        "  label STRING\n",
        ");\n",
        "\n",
        "insert into `test_dataset.ml_dataset`\n",
        "select id,\n",
        "  anomalyID,\n",
        "  IFNULL(srcIP, '0') as srcIP, \n",
        "  IFNULL(srcPort, '0') as srcPort, \n",
        "  IFNULL(dstIP, '0') as dstIP, \n",
        "  IFNULL(dstPort, '0') as dstPort, \n",
        "  IFNULL(taxonomy, '0') as taxonomy, \n",
        "  IFNULL(heuristic, '0') as heuristic, \n",
        "  IFNULL(distance, '0') as distance, \n",
        "  IFNULL(nbDetectors, '0') as nbDetectors, \n",
        "  IFNULL(label, '0') as label\n",
        "from\n",
        "\t(select row_number() over() as ID,\n",
        "\tanomalyID, \n",
        "\tcast(_srcIP as string) as srcIP, \n",
        "\tcast(_srcPort as string) as srcPort,\n",
        "\tcast(_dstIP as string) as dstIP, \n",
        "\tcast(_dstPort as string) as dstPort, \n",
        "\tcast(_taxonomy as string) as taxonomy,\n",
        "\t'' as heuristic,\n",
        "\tcast(_heuristic as string) as distance, \n",
        "\tcast(_distance as string) as nbDetectors, \n",
        "\tcast(_nbDetectors as string) as label \n",
        "\t# cast(_label as string) as label\n",
        "\tfrom `test_dataset.20210528_anomalous_suspicious`\n",
        "\t \n",
        "\tunion all \n",
        "\n",
        "\tselect row_number() over() as ID,\n",
        "\trow_number() over() as anomalyID,\n",
        "\tcast(anomalyID as string) as srcIP,\n",
        "\tcast(_srcIP as string) as srcPort, \n",
        "\tcast(_srcPort as string) as dstIP,\n",
        "\tcast(_dstIP as string) as dstPort, \n",
        "\tcast(_dstPort as string) as taxonomy, \n",
        "\tcast(_taxonomy as string) as heuristic, \n",
        "\tcast(_heuristic as string) as distance, \n",
        "\tcast(_distance as string) as nbDetectors, \n",
        "\tcast(_nbDetectors as string) as label\n",
        "\t# cast(_label as string) as label \n",
        "\tfrom `test_dataset.20210528_notice`\n",
        "\t);\n",
        "\n",
        "create or replace table `test_dataset.training_dataset`(\n",
        "  id INT64,\n",
        "  anomalyID INT64,\n",
        "  srcIP STRING, \n",
        "  srcPort STRING, \n",
        "  dstIP STRING, \n",
        "  dstPort STRING, \n",
        "  taxonomy STRING, \n",
        "  heuristic STRING, \n",
        "  distance STRING, \n",
        "  nbDetectors STRING, \n",
        "  label STRING\n",
        ");\n",
        "\n",
        "insert into `test_dataset.training_dataset` \n",
        "select * \n",
        "from `test_dataset.ml_dataset` TABLESAMPLE SYSTEM (80 PERCENT)\n",
        "where rand() < 0.8;\n",
        "\n",
        "create or replace table `test_dataset.testing_dataset`(\n",
        "  id INT64,\n",
        "  anomalyID INT64,\n",
        "  srcIP STRING, \n",
        "  srcPort STRING, \n",
        "  dstIP STRING, \n",
        "  dstPort STRING, \n",
        "  taxonomy STRING, \n",
        "  heuristic STRING, \n",
        "  distance STRING, \n",
        "  nbDetectors STRING, \n",
        "  label STRING\n",
        ");\n",
        "\n",
        "insert into `test_dataset.testing_dataset` \n",
        "select * \n",
        "from `test_dataset.ml_dataset` as t1 \n",
        "where not exists(select 1 from `test_dataset.training_dataset` as t2 where t1.id = t2.id)\n",
        "\n"
      ],
      "metadata": {
        "id": "zGdV073isCXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "select count(*) from `test_dataset.ml_dataset`; # 482\n",
        "\n",
        "select count(*) from `test_dataset.training_dataset`;  # 387\n",
        "\n",
        "select count(*) from `test_dataset.testing_dataset`; # 19"
      ],
      "metadata": {
        "id": "BnVmGE2qvxVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Model in Bigquery from training data"
      ],
      "metadata": {
        "id": "RcgUi_q7LtN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CREATE OR REPLACE MODEL `test_dataset.test_model_logistic_reg`\n",
        "OPTIONS(model_type='LOGISTIC_REG', INPUT_LABEL_COLS = ['label']) AS\n",
        "\tselect anomalyID, \n",
        "\tsrcIP, \n",
        "\tsrcPort, \n",
        "\tdstIP, \n",
        "\tdstPort, \n",
        "\ttaxonomy, \n",
        "\theuristic, \n",
        "\tdistance, \n",
        "\tnbDetectors, \n",
        "\tlabel \n",
        "\tfrom `test_dataset.training_dataset`"
      ],
      "metadata": {
        "id": "E0_XZnzeLvy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model produced can be queried. Based on the prior query you now have a new model available. You can use the ML.EVALUATE function (documentation) to see the evaluation metrics of all the created models (one per item):"
      ],
      "metadata": {
        "id": "lOar4cFsMRkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EVALUATE(MODEL `test_dataset.test_model_logistic_reg`)"
      ],
      "metadata": {
        "id": "SSxgYYjiOOgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.PREDICT(MODEL `test_dataset.test_model_logistic_reg`,\n",
        "    (\n",
        "    SELECT\n",
        "      * except(id, label)\n",
        "    FROM\n",
        "      `test_dataset.testing_dataset`))"
      ],
      "metadata": {
        "id": "DK1Tqe_ZP4NM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}