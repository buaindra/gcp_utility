{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo-DicomBeamPipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Apache Beam\n",
        "> Apache beam official documentation: https://beam.apache.org/documentation/io/built-in/\n",
        "\n"
      ],
      "metadata": {
        "id": "ID7W0eT3vbSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN882KJXhXP3"
      },
      "outputs": [],
      "source": [
        "# Apache Beam, Python package\n",
        "# apache_beam[gcp]\n",
        "!pip install apache_beam[interactive]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python package for dicom data processing\n",
        "!pip install pydicom"
      ],
      "metadata": {
        "id": "B40yG0WbjDac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample data downloaded from **Kaggle**\n",
        "##### Ref for how to setup kaggle access token with colab: https://www.kaggle.com/general/74235\n",
        "> Kaggle Site:  \n",
        "1. Dicom Data: https://www.kaggle.com/carlossalazar/dicomfolders\n",
        ">\n",
        ">"
      ],
      "metadata": {
        "id": "mf7VtUqGjaOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "7sE65BElq6oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload the kaggle.json (accen token)\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "KtPyuPGnvS-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -r ~/.kaggle"
      ],
      "metadata": {
        "id": "wIDkH8Nnz3P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "uniMG6pywDQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!kaggle datasets list "
      ],
      "metadata": {
        "id": "7Shmo47xjZoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download carlossalazar/dicomfolders"
      ],
      "metadata": {
        "id": "O8iek0Ef8DC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/sample_data/dicom_input;\n",
        "!unzip /content/dicomfolders.zip;"
      ],
      "metadata": {
        "id": "s-K-SoqEtnF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/Encapsulated1.dcm /content/sample_data/dicom_input/\n",
        "!mv /content/Encapsulated2.dcm /content/sample_data/dicom_input/\n",
        "!mv /content/Encapsulated3.dcm /content/sample_data/dicom_input/\n",
        "!mv /content/Encapsulated5.dcm /content/sample_data/dicom_input/"
      ],
      "metadata": {
        "id": "yUqTMSFGviaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dicom Data process"
      ],
      "metadata": {
        "id": "0PpxqgOKC4HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the apache beam modules\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.io import fileio\n",
        "\n",
        "# create the beam pipeline options\n",
        "pipeline_option = PipelineOptions()"
      ],
      "metadata": {
        "id": "IOKwz8Z3C_or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> sample csv file read and using read_utf8\n",
        ">\n",
        "> create pipeline and individual pcollection"
      ],
      "metadata": {
        "id": "vmCkOz5R1nG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample csv file read\n",
        "pipe = beam.Pipeline(options = pipeline_option)\n",
        "\n",
        "pcol_file_pattern = (pipe | fileio.MatchFiles(file_pattern=\"/content/sample_data/california_housing_test.csv\"))\n",
        "pcol_file_readmatches = (pcol_file_pattern | fileio.ReadMatches())\n",
        "pcol_read_utf8 = (\n",
        "    pcol_file_readmatches | beam.Map(lambda x: x.read_utf8())\n",
        ")\n",
        "pcol_print = (pcol_read_utf8 | beam.Map(print))\n",
        "\n",
        "pipe.run()"
      ],
      "metadata": {
        "id": "uG98aLLLv0Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> error for can't convert dicom file to utf-8 format\n",
        ">\n",
        "``` python3\n",
        "UnicodeDecodeError: 'utf-8 [while running '[14]: Map(<lambda at <ipython-input-14-b5478eabd99b>:6>)']' codec can't decode byte 0x88 in position 140: invalid start byte\n",
        "```"
      ],
      "metadata": {
        "id": "lbi3n_ruzSgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not able to read the dicom file utf-8 format\n",
        "with beam.Pipeline(options=pipeline_option) as dicom_pipeline:\n",
        "  pcol01 = (\n",
        "      dicom_pipeline | fileio.MatchFiles(file_pattern=\"/content/sample_data/dicom_input/*.dcm\")\n",
        "                     | fileio.ReadMatches()\n",
        "                     | beam.Map(lambda x: x.read_utf8())\n",
        "                     | beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "id": "anHyzuvpOj7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicom Data Dictionary\n",
        "from pydicom.datadict import DicomDictionary\n",
        "\n",
        "for key, value in DicomDictionary.items():\n",
        "  print(\"key: {} value: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "mIb_gewX_jiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Read and print/write Dicom Metadata\n",
        ">\n",
        "> **ParDo, DoFn** and **Map function**"
      ],
      "metadata": {
        "id": "81oI32ho21Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pydicom\n",
        "from pydicom.datadict import DicomDictionary\n",
        "\n",
        "class ReadDicomToJson(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    #print(element.metadata.path)\n",
        "    dicom_data = pydicom.dcmread(element.metadata.path)\n",
        "    dicom_json = dicom_data.to_json_dict()\n",
        "    yield dicom_json\n",
        "\n",
        "class DicomJson_Transformation(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    new_dicom_json = {}\n",
        "    for key, value in element.items():\n",
        "      for dkey, dvalue in DicomDictionary.items():\n",
        "        column = \"_\"+ str(key) + \"_\" +value.get(\"vr\", \"\")\n",
        "        if int(key, 16) == dkey:\n",
        "          column = str(dvalue[4])\n",
        "          break\n",
        "      data = value.get(\"Value\", \"\")\n",
        "      if type(data) == list and len(data) > 1:\n",
        "        row = str(data)\n",
        "      elif type(data) == list and len(data) == 1:\n",
        "        row = str(data[0])\n",
        "      else:\n",
        "        row = \"\"\n",
        "      new_dicom_json[column] = row\n",
        "    yield str(new_dicom_json)\n",
        "\n",
        "def element_print(element):\n",
        "  print(element)\n",
        "\n",
        "\n",
        "with beam.Pipeline(options=pipeline_option) as dicom_pipeline:\n",
        "  pcol01 = (\n",
        "      dicom_pipeline | fileio.MatchFiles(file_pattern=\"/content/sample_data/dicom_input/Encapsulated5.dcm\")\n",
        "                     | fileio.ReadMatches()\n",
        "                     | beam.ParDo(ReadDicomToJson())\n",
        "                     | beam.ParDo(DicomJson_Transformation())\n",
        "                     #| beam.Map(element_print)\n",
        "                     | fileio.WriteToFiles(\"/content/sample_data/dicom_out\")\n",
        "  )"
      ],
      "metadata": {
        "id": "xkZzcQs4JS-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Basic transformation **Map, Flatmap, Filter**\n",
        ">\n",
        "> Create **in-memory data** in beam"
      ],
      "metadata": {
        "id": "XDcNiXBQ36Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emp_data_01 = {\n",
        "    \"name\": \"Indranil\"\n",
        "    , \"company\": \"HCL\"\n",
        "    , \"experience\": 7\n",
        "    , \"tech\": [\"python\", \"composer\", \"dataflow\"]\n",
        "}\n",
        "\n",
        "emp_data_02 = {\n",
        "    \"name\": \"Mayank\"\n",
        "    , \"company\": \"HCL\"\n",
        "    , \"experience\": 17\n",
        "    , \"tech\": [\"python\", \"composer\", \"dataflow\", \"go\"]\n",
        "}\n",
        "\n",
        "emp_data_03 = {\n",
        "    \"name\": \"Raj\"\n",
        "    , \"company\": \"Google\"\n",
        "    , \"experience\": 15\n",
        "    , \"tech\": [\"python\", \"composer\", \"dataflow\", \"go\"]\n",
        "}\n",
        "\n",
        "memory_data = []\n",
        "memory_data.append(emp_data_01)\n",
        "memory_data.append(emp_data_02)\n",
        "memory_data.append(emp_data_03)\n",
        "\n",
        "print(memory_data)\n"
      ],
      "metadata": {
        "id": "Tf2liExp35uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from apache_beam.typehints.typehints import Iterable\n",
        "pipe1 = beam.Pipeline()\n",
        "pcol1 = (pipe1 | beam.Create(memory_data))\n",
        "pcol2 = (pcol1 | beam.Map(lambda x: x[\"company\"] == \"HCL\"))\n",
        "pcol3 = (pcol2 | beam.Map(lambda x: print(x)))\n",
        "\n",
        "pipe1.run()"
      ],
      "metadata": {
        "id": "EN30xRmtALuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from apache_beam.typehints.typehints import Iterable\n",
        "pipe1 = beam.Pipeline()\n",
        "pcol1 = (pipe1 | beam.Create(memory_data))\n",
        "pcol2 = (pcol1 | beam.Filter(lambda x: x[\"company\"] == \"HCL\"))\n",
        "pcol3 = (pcol2 | beam.Map(lambda x: print(x)))\n",
        "\n",
        "pipe1.run()"
      ],
      "metadata": {
        "id": "d1qhwo5AOEOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i0ScnJsSOcDP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}