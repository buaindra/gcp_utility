{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Composer_DynamicTask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZAldjgl7GFv5o9HlpBmrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buaindra/gcp_utility/blob/main/gcp/composer/dags/Composer_DynamicTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic Task Creation"
      ],
      "metadata": {
        "id": "K7zonC1PwAld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYm3BLB5v9BG"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "gsutil cp/working/dynamic_task_group_dag.py gs://us-centrall test-dcd1a744-bucket/dags/\n",
        "gsutil cp/working/ConfigFile.properties gs://us-central1-test-dcd1a744-bucket/data/\n",
        "'''\n",
        "\n",
        "import string\n",
        "from airflow import DAG\n",
        "from airflow.operators.dummy import DummyOperator\n",
        "from airflow.operators.python import BranchPythonOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
        "from airflow.utils.task_group import TaskGroup\n",
        "from airflow import models\n",
        "from datetime import datetime, timedelta\n",
        "from airflow.models.param import Param  #added this to use Param object\n",
        "from airflow.models import Variable  #added this to use Variable\n",
        "import logging  #added this to use Logging INFO\n",
        "import configparser\n",
        "\n",
        "#import os\n",
        "#import numpy as np  #for np. fromiter\n",
        "\n",
        "project_id=models.Variable.get(\"project_id\"))\n",
        "region=models.Variable.get(\"region\")\n",
        "\n",
        "env \"DEV\n",
        "config=confignarser.ConfigParser()\n",
        "config.read(/home/airflow/ges/data/ConfigFile.properties\")\n",
        "default_tables=config.get(env, \"tables_name\").split(\", \")[:1]\n",
        "Logging.info(f\"{default_tables}\")\n",
        "\n",
        "# hard coded table\n",
        "\n",
        "# default_tables = []\n",
        "# for i in range (1,11):\n",
        "#     table_name = \"table_\" + str(i) \n",
        "#     default_tables.append(table_name)\n",
        "\n",
        "default_args = {\n",
        "    \"start_date': datetime (2022, 3, 1), #example date\n",
        "    \"project_id\": project_id,\n",
        "    \"region\": region,\n",
        "    \"depends_on_past\" : False,\n",
        "    \"retries\": 1,\n",
        "    \"retry_delay\": timedelta (minutes=3),\n",
        "}\n",
        "\n",
        "##Please replace the function with your cloudsql config table details. ##This function will read the config table and return the table names t def read_config_db(**kwargs):\n",
        "#SRC TBL NM = kwargs.get('SRC_TBL_NM\")\n",
        "\n",
        "def read_config_db(**kwargs):\n",
        "    #SRC_TBL_NM = kwargs.get(\"SRC_TBL_NM\", [])\n",
        "    SRC_TBL_NM = kwargs[\"dag_run\"].conf.get(\"SRC_TBL_NM\", [])\n",
        "    logging.info(\"Current SRC TBL NM value is \" + str(SRC_TBL_NM))\n",
        "\n",
        "    where additional = \"\"\n",
        "    if (SRC TBL NM != \"ALL\" and type (SRC TBL NM) == list): \n",
        "        for i in SRC_TBL_NM:\n",
        "            where_additional = where_additional + \"'\" + str(i) + \"', \"\n",
        "        where_additional = \"where table name in (\" + where additional[:-2] + \")\"\n",
        "\n",
        "    query = \"SELECT table_name FROM config_db\" + where_additional + \";\" \n",
        "    #query = \"SELECT table_name FROM config_db;\"\n",
        "    logging.info(\"Current query value is \" + str(query))\n",
        "\n",
        "    postgres=PostgresHook(\"postgres_default\")\n",
        "    conn = postgres.get_conn() \n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(query)\n",
        "    table_names = [i[0] for i in cursor.fetchall()] \n",
        "    logging.info(\"Return result set value is \" + str(table_names))\n",
        "\n",
        "    ti = kwargs['ti'] \n",
        "    # results = []\n",
        "    # if kwargs[\"dag_run\"].conf.get(\"SRC_TBL_NM\", \"\") == \"ALL\":\n",
        "        # results.extend(default_tables)\n",
        "    # else:\n",
        "        # results.extend(kwargs[\"dag_run\"].conf.get(\"SRC_TBL_NM\", []))\n",
        "    #ti.xcom_push(key= 'FINAL_SRC_TBL_NM', value=results) \n",
        "    # Logging.info(f\"{results = }\") \n",
        "    ti.xcom_push(key='FINAL_SRC_TBL_NM', value-table_names)\n",
        "\n",
        "\n",
        "def branching_func(**kwargs):\n",
        "    ti = kwargs['ti']\n",
        "    executable_tasks=ti.xcom_pull(key=\"FINAL_SRC_TBL_NM\", task_ids=\"read_con \n",
        "    #new_List = [\"tkl \"+str(table) for table in executable tasks] \n",
        "    new_list = [str(table)+\"_TaskGrp.tk1 \"+str(table) for table in executable_tasks] \n",
        "    logging.info(f\"executable_tasks (new_list =}\") \n",
        "    return new_list\n",
        "\n",
        "\n",
        "#this function will return the table list 5\n",
        "def return_config():\n",
        "    FINAL_SRC_TBL_NM = default_tables \n",
        "    logging.info(\"Current FINAL SRC TBL NM value is \" + str(FINAL_SRC_TBL_NM))\n",
        "    return FINAL_SRC_TBL_NM\n",
        "\n",
        "\n",
        "with DAG(\n",
        "    dag_id=\"TEST_PL_Indra\", \n",
        "    schedule interval=None,\n",
        "    tags=['ingestion'],\n",
        "    default_args=default_args, \n",
        "    catchup=False,\n",
        "    params={ \n",
        "        'SRC_TBL_NM': Param(\"ALL\", type=['string', 'array']), # default ALL and use json schema validata\n",
        "    },\n",
        ") as dag:\n",
        "\n",
        "    #Dummy DAGS\n",
        "    start=DummyOperator(task_id=\"start\", dag=dag) \n",
        "    end=DummyOperator(task_id=\"end\", dag-dag, trigger_rule=\"none_failed_or_ski\n",
        "\n",
        "    read_config_db = PythonOperator(\n",
        "        task_id='read_config_db,\n",
        "        dag=dag,\n",
        "        provide_context=True,\n",
        "        python_callable=read_config_db,\n",
        "    )\n",
        "\n",
        "    branch_task = BranchPythonOperator(\n",
        "        task_id='branch_task',\n",
        "        provide_context=True, \n",
        "        python_callable=_branching_func,\n",
        "        do_xcom_push-False,\n",
        "        dag=dag\n",
        "    )\n",
        "\n",
        "    # start >> read_config_db >> branch_task  \\\n",
        "    # >> [DummyOperator(task_id=f\"tk1_(table)\", dag=dag) for table in return_config()]  \\\n",
        "    # >> end\n",
        "\n",
        "    if return_config():\n",
        "        for table in return_config(): \n",
        "            taskname=table + \"_TaskGrp\"\n",
        "            with TaskGroup(taskname) as ingest_table_group:\n",
        "                tk1 = DummyOperator(task_id=f\"tkl_(table)\", dag=dag) \n",
        "                tk2 = DummyOperator(task_id-f\"tk2_(table)\", dag=dag)\n",
        "\n",
        "                branch_task >> tk1 >> tk2 >> end\n",
        "                logging.info(f\"{table = }\")\n",
        "\n",
        "    start >> read_config_db >> branch_task >> ingest_table_group >> end"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[DEV]\n",
        "tables_name = HR_Table, EMP_Table, Account_Table"
      ],
      "metadata": {
        "id": "jaKeSPAOBv8x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}