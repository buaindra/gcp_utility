{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kubernetes Notes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTCWdqdmLTy56jaAgxfzTB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buaindra/gcp_utility/blob/main/Docker_Kubernetes/Kubernetes_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kubernetes(COE : Container Orchestration Engine)\n",
        "1. Clustering:\n",
        "  1. create logical entity over 100 of machines\n",
        "2. Scheduling: \n",
        "  1. scheduling the job"
      ],
      "metadata": {
        "id": "G437k1laK7tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Other COEs:\n",
        "1. swarm:\n",
        "  1. Docker product \n",
        "  1. Easy to implement and learn.\n",
        "  2. have less feature than Kubernetes.\n",
        "2. Mesos:\n",
        "  1. Apache product\n",
        "  2. Not proper COE\n",
        "  3. Datacenter OS, act as a single super computer handling other parallel computers.\n",
        "  4. you can run docker/contatiners job, spark job, hadoop jobs, cron jobs using mesos.\n",
        "  4. marathon has been used with mesos to handle docker/container jobs."
      ],
      "metadata": {
        "id": "Yc46usDytBK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COEs basic task:\n",
        "1. High Availability\n",
        "1. Horizontal scalling\n",
        "2. load balancing\n",
        "3. fault tolerance"
      ],
      "metadata": {
        "id": "DuMsIDBfvCvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Namespace\n",
        ">> Partition of stacks/projects/\n",
        "> \n",
        "1. Kubernates act as a one single interface over 40 or 400 server (cluster manager)\n",
        "2. namespace helps to partition the cluster to provide diff views for different stacks/projects.\n",
        "3. you can set networks betweens namespaces, you can set quotas"
      ],
      "metadata": {
        "id": "aD9gOc0gM9-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> POD:\n",
        "1. Run 1 docker container in 1 pod (docker container ~ kubernates pod)\n",
        "1. U can create multiple container inside 1 pod to deploy multiple app/process\n",
        "2. Single container can handle single process easily, but to handle multiple process, it's tricky.\n",
        "3. Most 99% scenarios, 1 pod handle 1 container and 1 container handle 1 app\n",
        "4. Pods can't be shared across the host, songle pods can run on single host.\n",
        ">\n",
        "> Pod spec: (AKMS - yaml code)\n",
        "1. kubernates creates pod-specs when you need to run 2 app (2 containers) on a single pod means on a single host.\n",
        "1. A: api version\n",
        "2. K: kind\n",
        "3. M: Metadata (labels, tags)\n",
        "3. S: spec, container specifications with immage and host (replica set, update strategy, pod spec)\n",
        ">\n"
      ],
      "metadata": {
        "id": "oGLtcM3JM4a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replication Controller / Replica Set and Deployments\n",
        "> Fault tolerance\n",
        "> Self healing, vertical scalling\n",
        "> using lables/tags, replication controller decide which pods needs to be monitored \n",
        ">\n",
        "> Replica set is new feature and works on specific sets/version specified in Pod spec\n",
        ">\n",
        "> Replication Controller + rolling update = deployment\n",
        "> \n",
        "> Replicaset + update strategies = deployment \n",
        "> "
      ],
      "metadata": {
        "id": "LFAYd3EUNrKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Service discovery & Load Balancing\n",
        "> Using api, u don't need to hardcode endpoint ip\n",
        "> It will dynamically allot"
      ],
      "metadata": {
        "id": "jkIfOw-HCQbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other info\n",
        "> Docker:\n",
        "1. Docker has some limitation, that it can launch, build, deploy the application on a **single host**.\n",
        "\n",
        ">\n",
        "\n",
        ">> Docker compose\n",
        ">>\n",
        ">> Docker Container\n",
        "\n",
        "1. in docker, takes an application, convert into image using **dockerfile**, that images becomes portable runtime environment, also you have packaged the application requirements with that image. Then run it as container. **check flex template in dataflow**.\n",
        "\n",
        "2. "
      ],
      "metadata": {
        "id": "aPM1WJDkNBLc"
      }
    }
  ]
}