{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Azure_Databricks_Spark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHK/jVsuTB0zfA82BEcH/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buaindra/gcp_utility/blob/main/azure/colab/Azure_Databricks_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Azure Databricks and Spark\n",
        "### Ref:\n",
        "1. Coursera Course: https://www.coursera.org/learn/perform-data-science-with-azure-databricks/lecture/Wn6zD/explain-azure-databricks"
      ],
      "metadata": {
        "id": "erPC0ptSFVfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Databricks\n",
        "1. Databricks is a ETL tools. It supports spark."
      ],
      "metadata": {
        "id": "KWKyDthzGJWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark\n",
        "1. Spark is **100x times faster** than Map-Reduce. Its actually do parallel jobs on distributed data.\n",
        "2. Spark can be easily worked with Python, Scala, Java, R, **ease of use**.\n",
        "3. Sparks **combines SQL, streaming, complex analytics** (Machine Learning)\n",
        "4. Spark **can run anywhare** (Apache Hadoop, Apache Mesos, Databricks, Kubernates, Standalone Cluster etc.)\n",
        "5. *spark dataframe and pandas dataframes* are not similar. **Dataframe** is a data structure and inside it we can perform various operations.\n"
      ],
      "metadata": {
        "id": "RwJ8-jjoKk09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PySpark Ref:\n",
        "1. Youtube: \n",
        "  1. https://www.youtube.com/watch?v=_C8kWso4ne4&t=597s\n",
        "2. Spark Official Doc:\n",
        "  1. Python API Ref: https://spark.apache.org/docs/latest/api/python/reference/index.html\n",
        "\n",
        "\n",
        "#### PySpark:\n",
        "1. *PySpark is an interface for Apache Spark in Python*, is often used for large scale data.\n",
        "2. create and start **SparkSession** before writing pyspark\n",
        "3. when using **inferSchema=True** while read data from csv, please check the file size, as if inferSchema enabled, its reads the whole file once and provide the datatype of columns based on the data, otherwise, *by default all columns will be string*.\n",
        "4. "
      ],
      "metadata": {
        "id": "upru3DSMGMUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspall pyspark\n",
        "! pip install pyspark\n",
        "\n",
        "# Successfully installed py4j-0.10.9.3 pyspark-3.2.1"
      ],
      "metadata": {
        "id": "vBPxt0tzSNlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072730f5-10fe-4df4-b071-ec5d74244d0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 28 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 43.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=bde9cdb64760cc6e82b35e621017c9dcbde9fc466be1323067be601354af2571\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understand Pandas Dataframe"
      ],
      "metadata": {
        "id": "ZzZgDugkY84o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/sample_emp.csv\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU_M6u1nW_S1",
        "outputId": "4c15f671-8d67-486c-a168-c2fd2beb2f07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Name  age  Experience  Salary\n",
            "0      Krish   31          10   30000\n",
            "1  Sudhanshu   30           8   25000\n",
            "2      Sunny   29           4   20000\n",
            "3       Paul   24           3   20000\n",
            "4     Harsha   21           1   15000\n",
            "5    Shubham   23           2   18000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to start writing PySpark"
      ],
      "metadata": {
        "id": "CaSSOD4cZB5H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BUZ7Vl9GFOEt"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Practise\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SparkSession"
      ],
      "metadata": {
        "id": "ywQ7qNIgGQQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# debug SparkSession variable\n",
        "spark\n",
        "# print(spark.getActiveSession)\n",
        "# print(spark.version)\n",
        "# print(spark.conf)\n",
        "# print(spark.sparkContext)\n",
        "# print(spark._instantiatedSession)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "8ZSCGhB-GMdo",
        "outputId": "0b126444-c314-4d59-badf-e46602bc49e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f06b7017250>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8bdeb21e8c52:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practise</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to read csv file in pyspark"
      ],
      "metadata": {
        "id": "6e8hwoB_FCWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ps = spark.read.csv(\"/content/sample_emp.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "XwEeOtDXYvnO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fetch the data from spark dataframs"
      ],
      "metadata": {
        "id": "45ol6UWhGB0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display all dataframe rows and columns\n",
        "print(df_ps.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg-6FhwMFpmt",
        "outputId": "bd0303f8-9c98-4575-f552-1d2c05e05591"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display 2 records from top\n",
        "print(df_ps.show(2))  # similar with head(2) as its also showing top 2 records \n",
        "print(df_ps.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWduuTqbKbwi",
        "outputId": "54c4816c-9a55-4a02-e48f-95ee9f2fc8fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "+---------+---+----------+------+\n",
            "only showing top 2 rows\n",
            "\n",
            "None\n",
            "[Row(Name='Krish', age=31, Experience=10, Salary=30000), Row(Name='Sudhanshu', age=30, Experience=8, Salary=25000)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display 2 records from down\n",
        "print(df_ps.tail(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVFJCmccKhYc",
        "outputId": "0a32cca6-f05a-4752-8732-0f38c86dbbf6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(Name=None, age=34, Experience=10, Salary=38000), Row(Name=None, age=36, Experience=None, Salary=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check datatypes of dataframe\n",
        "1. using **printSchema()** method\n",
        "2. or using **dtypes** property\n"
      ],
      "metadata": {
        "id": "1IymH9nqY4sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display the dataframe schema\n",
        "# in pandas its, df.info()\n",
        "print(df_ps.printSchema())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlVZk3fGLNcn",
        "outputId": "5b2d117a-8b19-4397-e758-23f999bf073e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ps.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwLHm0LGZA3t",
        "outputId": "fdc48e65-d05e-485f-bc5e-bf497baf591d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Computes basic statistics for numeric and string columns.\n",
        "1. using **describe()**"
      ],
      "metadata": {
        "id": "oRsLbMfVffyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_ps.describe())\n",
        "\n",
        "print(df_ps.describe().show())\n",
        "\n",
        "print(df_ps.describe(\"age\").show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qg_u3xsd5GY",
        "outputId": "6286f35b-363a-4924-8b16-5321c7c8bec3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[summary: string, Name: string, age: string, Experience: string, Salary: string]\n",
            "+-------+------+------------------+------------------+-----------------+\n",
            "|summary|  Name|               age|        Experience|           Salary|\n",
            "+-------+------+------------------+------------------+-----------------+\n",
            "|  count|     7|                 8|                 7|                8|\n",
            "|   mean|  null|              28.5| 5.428571428571429|          25750.0|\n",
            "| stddev|  null|5.3718844791323335|3.8234863173611093|9361.776388210581|\n",
            "|    min|Harsha|                21|                 1|            15000|\n",
            "|    max| Sunny|                36|                10|            40000|\n",
            "+-------+------+------------------+------------------+-----------------+\n",
            "\n",
            "None\n",
            "+-------+------------------+\n",
            "|summary|               age|\n",
            "+-------+------------------+\n",
            "|  count|                 8|\n",
            "|   mean|              28.5|\n",
            "| stddev|5.3718844791323335|\n",
            "|    min|                21|\n",
            "|    max|                36|\n",
            "+-------+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display the dataframe columns\n",
        "print(df_ps.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NSiXKsQLNbI",
        "outputId": "1d009c09-3376-490b-a563-65692b1bc720"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Name', 'age', 'Experience', 'Salary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Differebce between show() and collect()\n",
        "\n",
        "\n",
        "|id | show() | collect()|\n",
        "|--- | --- | ---|\n",
        "|1 | Returns None, display the rows and columns as tabular format | Returns  all the records as list|\n",
        "\n",
        "\n",
        "```python\n",
        "# similar \n",
        "df_ps.select([\"Name\", \"age\"]).show()\n",
        "df_ps.select(\"Name\", \"age\").show()\n",
        "\n",
        "df_ps.select([\"Name\", \"age\"]).collect()\n",
        "df_ps.select(\"Name\", \"age\").collect()\n",
        "```"
      ],
      "metadata": {
        "id": "b6AvEtq2RBOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display specific columns and custom columns from dataframes\n",
        "\n",
        "df_ps_retirement_yr = df_ps.select(\"Name\", \"age\", (60-df_ps.age).alias(\"retirement_yr_remaining\")).collect() # create list of rows\n",
        "print(df_ps_retirement_yr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_97kx6kLNU0",
        "outputId": "d2176663-09c7-43a3-8b88-ef9c50f013d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(Name='Krish', age=31, retirement_yr_remaining=29), Row(Name='Sudhanshu', age=30, retirement_yr_remaining=30), Row(Name='Sunny', age=29, retirement_yr_remaining=31), Row(Name='Paul', age=24, retirement_yr_remaining=36), Row(Name='Harsha', age=21, retirement_yr_remaining=39), Row(Name='Shubham', age=23, retirement_yr_remaining=37), Row(Name='Mahesh', age=None, retirement_yr_remaining=None), Row(Name=None, age=34, retirement_yr_remaining=26), Row(Name=None, age=36, retirement_yr_remaining=24)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to add new/custom columns into dataframe using **select()** and **withcolumns()**\n",
        "#### Differences betwen select() and withcolumns()\n",
        "\n",
        "| id | select() | withcolumns() |\n",
        "|---|---|---|\n",
        "|1| "
      ],
      "metadata": {
        "id": "1ZT4PSlhhPUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_out_select = df_ps.select(\"name\",  \"age\", (60-df_ps.age).alias(\"retirement_yr_remaining\"))\n",
        "print(df_out_select.show())\n",
        "\n",
        "df_out_withcolumn = df_ps.withColumn(\"retirement_yr_remaining\", 60-df_ps.age)\n",
        "# df_out_withcolumn = df_ps.withColumn(\"retirement_yr_remaining\", 60-df_ps[\"age\"])  # df_ps.age and df_ps[\"age\"] are same\n",
        "print(df_out_withcolumn.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3lWoAH4Sm7m",
        "outputId": "87b739a7-d597-446e-c456-dacd7025e812"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+-----------------------+\n",
            "|     name| age|retirement_yr_remaining|\n",
            "+---------+----+-----------------------+\n",
            "|    Krish|  31|                     29|\n",
            "|Sudhanshu|  30|                     30|\n",
            "|    Sunny|  29|                     31|\n",
            "|     Paul|  24|                     36|\n",
            "|   Harsha|  21|                     39|\n",
            "|  Shubham|  23|                     37|\n",
            "|   Mahesh|null|                   null|\n",
            "|     null|  34|                     26|\n",
            "|     null|  36|                     24|\n",
            "+---------+----+-----------------------+\n",
            "\n",
            "None\n",
            "+---------+----+----------+------+-----------------------+\n",
            "|     Name| age|Experience|Salary|retirement_yr_remaining|\n",
            "+---------+----+----------+------+-----------------------+\n",
            "|    Krish|  31|        10| 30000|                     29|\n",
            "|Sudhanshu|  30|         8| 25000|                     30|\n",
            "|    Sunny|  29|         4| 20000|                     31|\n",
            "|     Paul|  24|         3| 20000|                     36|\n",
            "|   Harsha|  21|         1| 15000|                     39|\n",
            "|  Shubham|  23|         2| 18000|                     37|\n",
            "|   Mahesh|null|      null| 40000|                   null|\n",
            "|     null|  34|        10| 38000|                     26|\n",
            "|     null|  36|      null|  null|                     24|\n",
            "+---------+----+----------+------+-----------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to drop columns from pyspark dataframes"
      ],
      "metadata": {
        "id": "F8p_xWEHoad1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = df_out_withcolumn.drop(\"retirement_yr_remaining\")\n",
        "print(\"After dropping column\", df_out.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTUxh6UNLNOj",
        "outputId": "48268eb8-1186-441a-cd5b-02eaaae58a3f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n",
            "After dropping column None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to rename a column into Dataframe"
      ],
      "metadata": {
        "id": "wejKFty-ph_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_out_renamed = df_out.withColumnRenamed(\"Age\",\"Actual Age\")\n",
        "print(df_out.show())  # no changes reflected on original dataframe\n",
        "print(df_out_renamed.show())  # changes reflected on returned dataframe after withColumnRenamed()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRH_WoLwLNJB",
        "outputId": "d32aee4a-fe3f-4897-d5ad-a4973f7a36c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n",
            "None\n",
            "+---------+----------+----------+------+\n",
            "|     Name|Actual Age|Experience|Salary|\n",
            "+---------+----------+----------+------+\n",
            "|    Krish|        31|        10| 30000|\n",
            "|Sudhanshu|        30|         8| 25000|\n",
            "|    Sunny|        29|         4| 20000|\n",
            "|     Paul|        24|         3| 20000|\n",
            "|   Harsha|        21|         1| 15000|\n",
            "|  Shubham|        23|         2| 18000|\n",
            "|   Mahesh|      null|      null| 40000|\n",
            "|     null|        34|        10| 38000|\n",
            "|     null|        36|      null|  null|\n",
            "+---------+----------+----------+------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### how to drop rows which has null values\n",
        "\n",
        "##### drop parameters:\n",
        "1. *how* : str, optional\n",
        "  1. 'any' or 'all'.\n",
        "  2. If 'any', drop a row if it contains any nulls.\n",
        "  3. If 'all', drop a row only if all its values are null.\n",
        "\n",
        "2. *thresh*: int, optional\n",
        "  1. default None\n",
        "  2. If specified, drop rows that have less than thresh non-null values.\n",
        "  3. This overwrites the how parameter.\n",
        "\n",
        "3. *subset*: str, tuple or list, optional\n",
        "  1. optional list of column names to consider having null will be deleted."
      ],
      "metadata": {
        "id": "tkKQ3fyktbuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_out_renamed.na.drop(how=\"any\", thresh=1).show())\n",
        "print(df_out_renamed.na.drop(how=\"any\", subset=[\"Experience\"]).show())\n",
        "print(df_out_renamed.na.drop().show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyX3NydALM-Y",
        "outputId": "89d37ef0-c70c-44cd-fbd7-8295405e3c35"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+----------+------+\n",
            "|     Name|Actual Age|Experience|Salary|\n",
            "+---------+----------+----------+------+\n",
            "|    Krish|        31|        10| 30000|\n",
            "|Sudhanshu|        30|         8| 25000|\n",
            "|    Sunny|        29|         4| 20000|\n",
            "|     Paul|        24|         3| 20000|\n",
            "|   Harsha|        21|         1| 15000|\n",
            "|  Shubham|        23|         2| 18000|\n",
            "|   Mahesh|      null|      null| 40000|\n",
            "|     null|        34|        10| 38000|\n",
            "|     null|        36|      null|  null|\n",
            "+---------+----------+----------+------+\n",
            "\n",
            "None\n",
            "+---------+----------+----------+------+\n",
            "|     Name|Actual Age|Experience|Salary|\n",
            "+---------+----------+----------+------+\n",
            "|    Krish|        31|        10| 30000|\n",
            "|Sudhanshu|        30|         8| 25000|\n",
            "|    Sunny|        29|         4| 20000|\n",
            "|     Paul|        24|         3| 20000|\n",
            "|   Harsha|        21|         1| 15000|\n",
            "|  Shubham|        23|         2| 18000|\n",
            "|     null|        34|        10| 38000|\n",
            "+---------+----------+----------+------+\n",
            "\n",
            "None\n",
            "+---------+----------+----------+------+\n",
            "|     Name|Actual Age|Experience|Salary|\n",
            "+---------+----------+----------+------+\n",
            "|    Krish|        31|        10| 30000|\n",
            "|Sudhanshu|        30|         8| 25000|\n",
            "|    Sunny|        29|         4| 20000|\n",
            "|     Paul|        24|         3| 20000|\n",
            "|   Harsha|        21|         1| 15000|\n",
            "|  Shubham|        23|         2| 18000|\n",
            "+---------+----------+----------+------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to fill/handle missing values (null) in dataframe"
      ],
      "metadata": {
        "id": "NTDptUDxyA31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_out_renamed.na.fill(\"missing\", subset=[\"Name\", \"Actual Age\",\"Experience\"]).show())  # doesn't affect \"Actual Age\",\"Experience\" as their datatype is int\n",
        "print(df_out_renamed.na.fill({'name': 'missing', 'actual age': 0, 'salary': 0.00}).show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqFcqze2yAgn",
        "outputId": "34bf340c-c6bd-4aa7-f975-b704787a909b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+----------+------+\n",
            "|     Name|Actual Age|Experience|Salary|\n",
            "+---------+----------+----------+------+\n",
            "|    Krish|        31|        10| 30000|\n",
            "|Sudhanshu|        30|         8| 25000|\n",
            "|    Sunny|        29|         4| 20000|\n",
            "|     Paul|        24|         3| 20000|\n",
            "|   Harsha|        21|         1| 15000|\n",
            "|  Shubham|        23|         2| 18000|\n",
            "|   Mahesh|      null|      null| 40000|\n",
            "|  missing|        34|        10| 38000|\n",
            "|  missing|        36|      null|  null|\n",
            "+---------+----------+----------+------+\n",
            "\n",
            "None\n",
            "+---------+----------+----------+------+\n",
            "|     Name|Actual Age|Experience|Salary|\n",
            "+---------+----------+----------+------+\n",
            "|    Krish|        31|        10| 30000|\n",
            "|Sudhanshu|        30|         8| 25000|\n",
            "|    Sunny|        29|         4| 20000|\n",
            "|     Paul|        24|         3| 20000|\n",
            "|   Harsha|        21|         1| 15000|\n",
            "|  Shubham|        23|         2| 18000|\n",
            "|   Mahesh|         0|      null| 40000|\n",
            "|  missing|        34|        10| 38000|\n",
            "|  missing|        36|      null|     0|\n",
            "+---------+----------+----------+------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['age', 'Experience', 'Salary'], \n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"median\")\n",
        "\n",
        "# Add imputation cols to df\n",
        "imputer.fit(df_ps).transform(df_ps).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zhk4Ac8yAfD",
        "outputId": "6cccd788-6c1b-4f3c-a4ea-ea091fdbf0c3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|null|      null| 40000|         29|                 4|         40000|\n",
            "|     null|  34|        10| 38000|         34|                10|         38000|\n",
            "|     null|  36|      null|  null|         36|                 4|         20000|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EVFKGnsEyAbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RGn0FeaCyAZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5cYxPAmwyAXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kCM0DlFQyAVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_-xPlLrCLMwE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}